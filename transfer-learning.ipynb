{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning\n",
    "\n",
    "In this notebook we use **pre-trained** neural networks as a starting point for our own models. Other people have trained enormous general-purpose CNNs for image classification. We can exploit the features that these CNNs have found for our own image classification problem.\n",
    "\n",
    "Typically, transfer learning works by loading a pre-trained network and removing the final layer (which predicts class membership), since this will be particular to the problem used to train the original network. We then add on our own final layer, which contains our own output nodes. We then retrain the network (either just the final layer, or the whole network). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Sys.setenv(KERAS_BACKEND = \"tensorflow\")\n",
    "library(keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say where the data is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_directory <- \"data/invasives/train/\"\n",
    "validation_directory <- \"data/invasives/validation/\"\n",
    "test_directory <- \"data/invasives/test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And work out how many images we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_samples <- length(list.files(paste(train_directory,\"invasive\",sep=\"\"))) +\n",
    "    length(list.files(paste(train_directory,\"non_invasive\",sep=\"\")))\n",
    "\n",
    "validation_samples <- length(list.files(paste(validation_directory,\"invasive\",sep=\"\"))) +\n",
    "    length(list.files(paste(validation_directory,\"non_invasive\",sep=\"\")))\n",
    "\n",
    "test_samples <- length(list.files(paste(test_directory,\"invasive\",sep=\"\"))) +\n",
    "    length(list.files(paste(test_directory,\"non_invasive\",sep=\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "953"
      ],
      "text/latex": [
       "953"
      ],
      "text/markdown": [
       "953"
      ],
      "text/plain": [
       "[1] 953"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we will use the VGG16 pre-trained network. This network needs 224x224 images, so we set desired image height and width accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_height <- 224\n",
    "img_width <- 224\n",
    "batch_size <- 16\n",
    "epochs <- 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator <- flow_images_from_directory(\n",
    "  train_directory, \n",
    "  generator = image_data_generator(),\n",
    "  target_size = c(img_height, img_width),\n",
    "  color_mode = \"rgb\",\n",
    "  class_mode = \"binary\", \n",
    "  batch_size = batch_size, \n",
    "  shuffle = TRUE,\n",
    "  seed = 123)\n",
    "\n",
    "validation_generator <- flow_images_from_directory(\n",
    "  validation_directory, \n",
    "  generator = image_data_generator(), \n",
    "  target_size = c(img_height, img_width), \n",
    "  color_mode = \"rgb\", \n",
    "  classes = NULL,\n",
    "  class_mode = \"binary\", \n",
    "  batch_size = batch_size, \n",
    "  shuffle = TRUE,\n",
    "  seed = 123)\n",
    "\n",
    "test_generator <- flow_images_from_directory(\n",
    "  test_directory, \n",
    "  generator = image_data_generator(),\n",
    "  target_size = c(img_height, img_width), \n",
    "  color_mode = \"rgb\", \n",
    "  class_mode = \"binary\", \n",
    "  batch_size = 1,\n",
    "  shuffle = FALSE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading pre-trained model and adding custom layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model <- application_vgg16(weights = \"imagenet\", \n",
    "                                       include_top = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add our custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions <- base_model$output %>% \n",
    "  layer_global_average_pooling_2d() %>% \n",
    "  layer_dense(units = 1024, activation = \"relu\") %>% \n",
    "  layer_dense(units = 1, activation = \"sigmoid\")\n",
    "\n",
    "model <- keras_model(inputs = base_model$input, \n",
    "                     outputs = predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model %>% compile(\n",
    "  loss = \"binary_crossentropy\",\n",
    "  optimizer = optimizer_sgd(lr = 0.0001, \n",
    "                            momentum = 0.9, \n",
    "                            decay = 1e-5),\n",
    "  metrics = \"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model %>% fit_generator(\n",
    "  train_generator,\n",
    "  steps_per_epoch = 1, \n",
    "  epochs = 1, \n",
    "  validation_data = validation_generator,\n",
    "  validation_steps = 1,\n",
    "  verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model\n",
       "________________________________________________________________________________\n",
       "Layer (type)                        Output Shape                    Param #     \n",
       "================================================================================\n",
       "input_1 (InputLayer)                (None, None, None, 3)           0           \n",
       "________________________________________________________________________________\n",
       "block1_conv1 (Conv2D)               (None, None, None, 64)          1792        \n",
       "________________________________________________________________________________\n",
       "block1_conv2 (Conv2D)               (None, None, None, 64)          36928       \n",
       "________________________________________________________________________________\n",
       "block1_pool (MaxPooling2D)          (None, None, None, 64)          0           \n",
       "________________________________________________________________________________\n",
       "block2_conv1 (Conv2D)               (None, None, None, 128)         73856       \n",
       "________________________________________________________________________________\n",
       "block2_conv2 (Conv2D)               (None, None, None, 128)         147584      \n",
       "________________________________________________________________________________\n",
       "block2_pool (MaxPooling2D)          (None, None, None, 128)         0           \n",
       "________________________________________________________________________________\n",
       "block3_conv1 (Conv2D)               (None, None, None, 256)         295168      \n",
       "________________________________________________________________________________\n",
       "block3_conv2 (Conv2D)               (None, None, None, 256)         590080      \n",
       "________________________________________________________________________________\n",
       "block3_conv3 (Conv2D)               (None, None, None, 256)         590080      \n",
       "________________________________________________________________________________\n",
       "block3_pool (MaxPooling2D)          (None, None, None, 256)         0           \n",
       "________________________________________________________________________________\n",
       "block4_conv1 (Conv2D)               (None, None, None, 512)         1180160     \n",
       "________________________________________________________________________________\n",
       "block4_conv2 (Conv2D)               (None, None, None, 512)         2359808     \n",
       "________________________________________________________________________________\n",
       "block4_conv3 (Conv2D)               (None, None, None, 512)         2359808     \n",
       "________________________________________________________________________________\n",
       "block4_pool (MaxPooling2D)          (None, None, None, 512)         0           \n",
       "________________________________________________________________________________\n",
       "block5_conv1 (Conv2D)               (None, None, None, 512)         2359808     \n",
       "________________________________________________________________________________\n",
       "block5_conv2 (Conv2D)               (None, None, None, 512)         2359808     \n",
       "________________________________________________________________________________\n",
       "block5_conv3 (Conv2D)               (None, None, None, 512)         2359808     \n",
       "________________________________________________________________________________\n",
       "block5_pool (MaxPooling2D)          (None, None, None, 512)         0           \n",
       "________________________________________________________________________________\n",
       "global_average_pooling2d_1 (GlobalA (None, 512)                     0           \n",
       "________________________________________________________________________________\n",
       "dense_1 (Dense)                     (None, 1024)                    525312      \n",
       "________________________________________________________________________________\n",
       "dense_2 (Dense)                     (None, 1)                       1025        \n",
       "================================================================================\n",
       "Total params: 15,241,025\n",
       "Trainable params: 15,241,025\n",
       "Non-trainable params: 0\n",
       "________________________________________________________________________________\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in evaluate_generator(., model, test_generator, steps = 1, max_queue_size = 1): unused argument (test_generator)\n",
     "output_type": "error",
     "traceback": [
      "Error in evaluate_generator(., model, test_generator, steps = 1, max_queue_size = 1): unused argument (test_generator)\nTraceback:\n",
      "1. model %>% evaluate_generator(model, test_generator, steps = 1, \n .     max_queue_size = 1)",
      "2. withVisible(eval(quote(`_fseq`(`_lhs`)), env, env))",
      "3. eval(quote(`_fseq`(`_lhs`)), env, env)",
      "4. eval(quote(`_fseq`(`_lhs`)), env, env)",
      "5. `_fseq`(`_lhs`)",
      "6. freduce(value, `_function_list`)",
      "7. withVisible(function_list[[k]](value))",
      "8. function_list[[k]](value)"
     ]
    }
   ],
   "source": [
    "model %>% evaluate_generator(model, test_generator, steps = 1,\n",
    "                            max_queue_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in as.integer(max_queue_size): cannot coerce type 'environment' to vector of type 'integer'\n",
     "output_type": "error",
     "traceback": [
      "Error in as.integer(max_queue_size): cannot coerce type 'environment' to vector of type 'integer'\nTraceback:\n",
      "1. model %>% predict_generator(model, test_generator, steps = 1)",
      "2. withVisible(eval(quote(`_fseq`(`_lhs`)), env, env))",
      "3. eval(quote(`_fseq`(`_lhs`)), env, env)",
      "4. eval(quote(`_fseq`(`_lhs`)), env, env)",
      "5. `_fseq`(`_lhs`)",
      "6. freduce(value, `_function_list`)",
      "7. withVisible(function_list[[k]](value))",
      "8. function_list[[k]](value)",
      "9. predict_generator(., model, test_generator, steps = 1)"
     ]
    }
   ],
   "source": [
    "model %>% predict_generator(model,\n",
    "                           test_generator,\n",
    "                           steps = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
