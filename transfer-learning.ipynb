{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning\n",
    "\n",
    "In this notebook we use **pre-trained** neural networks as a starting point for our own models. Other people have trained enormous general-purpose CNNs for image classification. We can exploit the features that these CNNs have found for our own image classification problem.\n",
    "\n",
    "Typically, transfer learning works by loading a pre-trained network and removing the final layer (which predicts class membership), since this will be particular to the problem used to train the original network. We then add on our own final layer, which contains our own output nodes. We then retrain the network (either just the final layer, or the whole network). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Sys.setenv(KERAS_BACKEND = \"tensorflow\")\n",
    "library(keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say where the data is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_directory <- \"data/invasives/sample/train/\"\n",
    "validation_directory <- \"data/invasives/sample/validation/\"\n",
    "test_directory <- \"data/invasives/sample/test/\"\n",
    "\n",
    "# once you are satisfied the code is working, run full dataset\n",
    "# train_directory <- \"data/invasives/train/\"\n",
    "# validation_directory <- \"data/invasives/validation/\"\n",
    "# test_directory <- \"data/invasives/test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And work out how many images we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_samples <- length(list.files(paste(train_directory,\"invasive\",sep=\"\"))) +\n",
    "    length(list.files(paste(train_directory,\"non_invasive\",sep=\"\")))\n",
    "\n",
    "validation_samples <- length(list.files(paste(validation_directory,\"invasive\",sep=\"\"))) +\n",
    "    length(list.files(paste(validation_directory,\"non_invasive\",sep=\"\")))\n",
    "\n",
    "test_samples <- length(list.files(paste(test_directory,\"invasive\",sep=\"\"))) +\n",
    "    length(list.files(paste(test_directory,\"non_invasive\",sep=\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we will use the VGG16 pre-trained network. This network needs 224x224 images, so we set desired image height and width accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_height <- 224\n",
    "img_width <- 224\n",
    "batch_size <- 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator <- flow_images_from_directory(\n",
    "  train_directory, \n",
    "  generator = image_data_generator(),\n",
    "  target_size = c(img_height, img_width),\n",
    "  color_mode = \"rgb\",\n",
    "  class_mode = \"binary\", \n",
    "  batch_size = batch_size, \n",
    "  shuffle = TRUE,\n",
    "  seed = 123)\n",
    "\n",
    "validation_generator <- flow_images_from_directory(\n",
    "  validation_directory, \n",
    "  generator = image_data_generator(), \n",
    "  target_size = c(img_height, img_width), \n",
    "  color_mode = \"rgb\", \n",
    "  classes = NULL,\n",
    "  class_mode = \"binary\", \n",
    "  batch_size = batch_size, \n",
    "  shuffle = TRUE,\n",
    "  seed = 123)\n",
    "\n",
    "test_generator <- flow_images_from_directory(\n",
    "  test_directory, \n",
    "  generator = image_data_generator(),\n",
    "  target_size = c(img_height, img_width), \n",
    "  color_mode = \"rgb\", \n",
    "  class_mode = \"binary\", \n",
    "  batch_size = 1,\n",
    "  shuffle = FALSE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading pre-trained model and adding custom layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model <- application_vgg16(weights = \"imagenet\", \n",
    "                                       include_top = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add our custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions <- base_model$output %>% \n",
    "  layer_global_average_pooling_2d() %>% \n",
    "  layer_dense(units = 1024, activation = \"relu\") %>% \n",
    "  layer_dense(units = 1, activation = \"sigmoid\")\n",
    "\n",
    "model <- keras_model(inputs = base_model$input, \n",
    "                     outputs = predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model %>% compile(\n",
    "  loss = \"binary_crossentropy\",\n",
    "  optimizer = optimizer_sgd(lr = 0.0001, \n",
    "                            momentum = 0.9, \n",
    "                            decay = 1e-5),\n",
    "  metrics = \"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model %>% fit_generator(\n",
    "  train_generator,\n",
    "  steps_per_epoch = as.integer(train_samples / batch_size), \n",
    "  epochs = 5, \n",
    "  validation_data = validation_generator,\n",
    "  validation_steps = as.integer(validation_samples / batch_size),\n",
    "  verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model %>% evaluate_generator(\n",
    "    test_generator,\n",
    "    steps = test_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
